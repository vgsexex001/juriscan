"use client";

import { useState, useRef, useCallback, useEffect } from "react";
import { CHAT_ATTACHMENT_LIMITS } from "@/types/chat";

interface AudioRecorderState {
  isRecording: boolean;
  isPaused: boolean;
  duration: number;
  audioBlob: Blob | null;
  audioUrl: string | null;
  error: string | null;
  isSupported: boolean;
}

interface UseAudioRecorderReturn extends AudioRecorderState {
  startRecording: () => Promise<void>;
  stopRecording: () => void;
  pauseRecording: () => void;
  resumeRecording: () => void;
  resetRecording: () => void;
}

// Obter MIME type suportado pelo navegador
function getSupportedMimeType(): string {
  if (typeof window === "undefined") return "audio/webm";

  const types = [
    "audio/webm;codecs=opus",
    "audio/webm",
    "audio/mp4",
    "audio/ogg;codecs=opus",
    "audio/ogg",
  ];

  for (const type of types) {
    if (MediaRecorder.isTypeSupported(type)) {
      console.log("游꿗 Using MIME type:", type);
      return type;
    }
  }

  console.warn("游꿗 No supported MIME type found, defaulting to audio/webm");
  return "audio/webm";
}

export function useAudioRecorder(): UseAudioRecorderReturn {
  const [state, setState] = useState<AudioRecorderState>({
    isRecording: false,
    isPaused: false,
    duration: 0,
    audioBlob: null,
    audioUrl: null,
    error: null,
    isSupported: false, // Ser치 atualizado no useEffect
  });

  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const streamRef = useRef<MediaStream | null>(null);
  const chunksRef = useRef<Blob[]>([]);
  const timerRef = useRef<ReturnType<typeof setInterval> | null>(null);
  const startTimeRef = useRef<number>(0);
  const pausedDurationRef = useRef<number>(0);
  const mimeTypeRef = useRef<string>("audio/webm");

  // Verificar suporte no cliente
  useEffect(() => {
    const checkSupport = () => {
      const hasMediaDevices = !!navigator?.mediaDevices?.getUserMedia;
      const hasMediaRecorder = typeof MediaRecorder !== "undefined";
      const isSupported = hasMediaDevices && hasMediaRecorder;

      console.log("游꿗 Audio recording support:", {
        hasMediaDevices,
        hasMediaRecorder,
        isSupported,
      });

      if (isSupported) {
        mimeTypeRef.current = getSupportedMimeType();
      }

      setState((prev) => ({ ...prev, isSupported }));
    };

    checkSupport();
  }, []);

  // Limpar recursos ao desmontar
  useEffect(() => {
    return () => {
      if (timerRef.current) {
        clearInterval(timerRef.current);
      }
      if (streamRef.current) {
        streamRef.current.getTracks().forEach((track) => track.stop());
      }
    };
  }, []);

  const stopTimer = useCallback(() => {
    if (timerRef.current) {
      clearInterval(timerRef.current);
      timerRef.current = null;
    }
  }, []);

  const stopRecording = useCallback(() => {
    console.log("游꿗 Stopping recording...");
    stopTimer();

    if (mediaRecorderRef.current && mediaRecorderRef.current.state !== "inactive") {
      mediaRecorderRef.current.stop();
    }
  }, [stopTimer]);

  const startTimer = useCallback(() => {
    startTimeRef.current = Date.now() - pausedDurationRef.current * 1000;

    timerRef.current = setInterval(() => {
      const elapsed = Math.floor((Date.now() - startTimeRef.current) / 1000);

      // Verificar limite de dura칞칚o
      if (elapsed >= CHAT_ATTACHMENT_LIMITS.maxAudioDuration) {
        console.log("游꿗 Max duration reached, stopping...");
        stopRecording();
        return;
      }

      setState((prev) => ({ ...prev, duration: elapsed }));
    }, 100);
  }, [stopRecording]);

  const startRecording = useCallback(async () => {
    console.log("游꿗 Starting recording...");

    if (!state.isSupported) {
      console.error("游꿗 Audio recording not supported");
      setState((prev) => ({
        ...prev,
        error: "Grava칞칚o de 치udio n칚o suportada neste navegador",
      }));
      return;
    }

    try {
      // Resetar estado
      chunksRef.current = [];
      pausedDurationRef.current = 0;

      if (state.audioUrl) {
        URL.revokeObjectURL(state.audioUrl);
      }

      // Solicitar permiss칚o do microfone
      console.log("游꿗 Requesting microphone permission...");
      const stream = await navigator.mediaDevices.getUserMedia({
        audio: {
          echoCancellation: true,
          noiseSuppression: true,
          sampleRate: 44100,
        },
      });

      console.log("游꿗 Microphone permission granted, stream:", stream.id);
      streamRef.current = stream;

      // Criar MediaRecorder com MIME type suportado
      const mimeType = mimeTypeRef.current;
      console.log("游꿗 Creating MediaRecorder with mimeType:", mimeType);

      const mediaRecorder = new MediaRecorder(stream, {
        mimeType,
        audioBitsPerSecond: 128000,
      });

      mediaRecorderRef.current = mediaRecorder;

      mediaRecorder.ondataavailable = (event) => {
        console.log("游꿗 Data available:", event.data.size, "bytes");
        if (event.data.size > 0) {
          chunksRef.current.push(event.data);
        }
      };

      mediaRecorder.onstop = () => {
        console.log("游꿗 Recording stopped, chunks:", chunksRef.current.length);

        if (chunksRef.current.length === 0) {
          console.error("游꿗 No audio data collected!");
          setState((prev) => ({
            ...prev,
            isRecording: false,
            error: "Nenhum 치udio foi gravado. Tente novamente.",
          }));
          return;
        }

        const blob = new Blob(chunksRef.current, { type: mimeType });
        const url = URL.createObjectURL(blob);

        console.log("游꿗 Audio blob created:", blob.size, "bytes");

        setState((prev) => ({
          ...prev,
          isRecording: false,
          isPaused: false,
          audioBlob: blob,
          audioUrl: url,
        }));

        // Parar stream
        if (streamRef.current) {
          streamRef.current.getTracks().forEach((track) => track.stop());
          streamRef.current = null;
        }
      };

      mediaRecorder.onerror = (event) => {
        console.error("游꿗 MediaRecorder error:", event);
        stopTimer();
        setState((prev) => ({
          ...prev,
          isRecording: false,
          error: "Erro ao gravar 치udio. Tente novamente.",
        }));
      };

      // Iniciar grava칞칚o - solicitar dados a cada 1 segundo
      mediaRecorder.start(1000);
      startTimer();

      console.log("游꿗 Recording started!");

      setState((prev) => ({
        ...prev,
        isRecording: true,
        isPaused: false,
        duration: 0,
        audioBlob: null,
        audioUrl: null,
        error: null,
      }));
    } catch (error) {
      console.error("游꿗 Error starting recording:", error);

      let errorMessage = "Erro ao iniciar grava칞칚o";
      if (error instanceof Error) {
        if (error.name === "NotAllowedError") {
          errorMessage = "Permiss칚o de microfone negada. Clique no 칤cone de cadeado na barra de endere칞o para permitir.";
        } else if (error.name === "NotFoundError") {
          errorMessage = "Nenhum microfone encontrado. Conecte um microfone e tente novamente.";
        } else if (error.name === "NotReadableError") {
          errorMessage = "Microfone est치 sendo usado por outro aplicativo.";
        } else if (error.name === "OverconstrainedError") {
          errorMessage = "Configura칞칚o de microfone n칚o suportada.";
        } else {
          errorMessage = `Erro: ${error.message}`;
        }
      }

      setState((prev) => ({ ...prev, error: errorMessage }));
    }
  }, [state.isSupported, state.audioUrl, startTimer, stopTimer]);

  const pauseRecording = useCallback(() => {
    if (mediaRecorderRef.current && mediaRecorderRef.current.state === "recording") {
      console.log("游꿗 Pausing recording...");
      mediaRecorderRef.current.pause();
      stopTimer();
      pausedDurationRef.current = state.duration;
      setState((prev) => ({ ...prev, isPaused: true }));
    }
  }, [state.duration, stopTimer]);

  const resumeRecording = useCallback(() => {
    if (mediaRecorderRef.current && mediaRecorderRef.current.state === "paused") {
      console.log("游꿗 Resuming recording...");
      mediaRecorderRef.current.resume();
      startTimer();
      setState((prev) => ({ ...prev, isPaused: false }));
    }
  }, [startTimer]);

  const resetRecording = useCallback(() => {
    console.log("游꿗 Resetting recording...");
    stopTimer();

    if (mediaRecorderRef.current && mediaRecorderRef.current.state !== "inactive") {
      mediaRecorderRef.current.stop();
    }

    if (streamRef.current) {
      streamRef.current.getTracks().forEach((track) => track.stop());
      streamRef.current = null;
    }

    if (state.audioUrl) {
      URL.revokeObjectURL(state.audioUrl);
    }

    chunksRef.current = [];
    pausedDurationRef.current = 0;
    mediaRecorderRef.current = null;

    setState((prev) => ({
      ...prev,
      isRecording: false,
      isPaused: false,
      duration: 0,
      audioBlob: null,
      audioUrl: null,
      error: null,
    }));
  }, [state.audioUrl, stopTimer]);

  return {
    ...state,
    startRecording,
    stopRecording,
    pauseRecording,
    resumeRecording,
    resetRecording,
  };
}
